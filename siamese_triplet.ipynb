{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_triplet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "csHAGAW8peFu"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import filetype\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import random\n",
        "import ssl\n",
        "import datetime\n",
        "import sys\n",
        "import copy\n",
        "from skimage.filters import threshold_yen\n",
        "from skimage.exposure import rescale_intensity\n",
        "from skimage.io import imread, imsave\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Activation, Flatten, Dense, Dropout\n",
        "from keras import backend as K\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ2XjvKo0cwm"
      },
      "source": [
        "#調整亮度與銳利度\n",
        "def automatic_brightness_and_contrast(image, clip_hist_percent=25):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
        "    hist_size = len(hist)\n",
        "    accumulator = []\n",
        "    accumulator.append(float(hist[0]))\n",
        "    for index in range(1, hist_size):\n",
        "        accumulator.append(accumulator[index -1] + float(hist[index]))\n",
        "    maximum = accumulator[-1]\n",
        "    clip_hist_percent *= (maximum/100.0)\n",
        "    clip_hist_percent /= 2.0\n",
        "    minimum_gray = 0\n",
        "    while accumulator[minimum_gray] < clip_hist_percent:\n",
        "        minimum_gray += 1\n",
        "    maximum_gray = hist_size -1\n",
        "    while accumulator[maximum_gray] >= (maximum - clip_hist_percent):\n",
        "        maximum_gray -= 1\n",
        "    alpha = 255 / (maximum_gray - minimum_gray)\n",
        "    beta = -minimum_gray * alpha\n",
        "\n",
        "    auto_result = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "    return (auto_result, alpha, beta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E04HKd0PAXir"
      },
      "source": [
        "def read_directory(directory_name,data,label,label_name,data_position):\n",
        "    global count_image\n",
        "    count_image_before = copy.deepcopy(count_image)\n",
        "    for filename in os.listdir(directory_name):\n",
        "      if filename == '.DS_Store':\n",
        "          continue\n",
        "      count_image+=1\n",
        "      img = tf.keras.preprocessing.image.load_img(directory_name + \"/\" + filename,target_size=(256,256,3)) #讀圖片\n",
        "      img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "      auto_result, alpha, beta = automatic_brightness_and_contrast(img) #亮度與銳利度調整\n",
        "      img = tf.keras.preprocessing.image.img_to_array(auto_result)\n",
        "      img = tf.keras.applications.densenet.preprocess_input(img) #densenet的顏色前處理\n",
        "      data.append(img)\n",
        "      label.append(label_name)\n",
        "    data_position.append((count_image_before,count_image))\n",
        "    print(count_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE78SfvrJ90c"
      },
      "source": [
        "train_dir = '' #輸入自己的資料夾路徑 形式：train/A/, train/B/, train/C/\n",
        "test_dir = '' #輸入自己的資料夾路徑 形式：test/A/, test/B/, test/C/\n",
        "\n",
        "train_data = [] \n",
        "train_label = []\n",
        "\n",
        "test_data = []\n",
        "test_label = []\n",
        "\n",
        "def load_data(img_dir,data,label,label_number,data_position):\n",
        "    for count,filename in enumerate(os.listdir(img_dir)):\n",
        "        if filename == '.DS_Store':\n",
        "                continue\n",
        "        if os.path.isfile(img_dir + '/' + filename):\n",
        "            print (\"it's a normal file\")\n",
        "        else:\n",
        "            print(filename+\" it's a folder\")\n",
        "            for folder in os.listdir(img_dir+'/'+filename):\n",
        "                if folder == '.DS_Store':\n",
        "                    continue \n",
        "                label_number+= 1\n",
        "                print(img_dir+'/'+filename+\"/\"+folder + \" : \"+str(label_number))\n",
        "                read_directory(img_dir+'/'+filename+\"/\"+folder,data,label,label_number,data_position)\n",
        "    return label_number  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEEE9rG7lb5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff955fb-4ec9-4e40-da9f-c10c0354195b"
      },
      "source": [
        "#記得label是從1開始 位置是從0\n",
        "\n",
        "count_folder_train = 0 #計算train有幾個資料夾\n",
        "count_image = 0  #計算多少張照片\n",
        "train_data_position = [] #train每一個類別的位置\n",
        "count_folder_train = load_data(train_dir,train_data,train_label,count_folder_train,train_data_position)\n",
        "print(count_folder_train)\n",
        "count_image_train = copy.deepcopy(count_image) #train總共有幾張\n",
        "\n",
        "count_folder_test = 0 #test有幾個資料夾\n",
        "count_image = 0 \n",
        "test_data_position = [] #test每一個類別的位置\n",
        "count_folder_test = load_data(test_dir,test_data,test_label,count_folder_test,test_data_position)\n",
        "print(count_folder_test)\n",
        "count_image_test  = copy.deepcopy(count_image) #test總共有多少張"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0tS6kq7kzhW"
      },
      "source": [
        "train_data, train_label = shuffle(train_data, train_label, random_state=0) #把資料打散,這樣取圖片的時候可以更隨機"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3gLp5WsRu_w"
      },
      "source": [
        "train_data = np.array(train_data)\n",
        "train_label = np.array(train_label)\n",
        "test_data = np.array(test_data)\n",
        "test_label = np.array(test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvKpZyVhOHSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c4f1c6-60b5-474b-ce16-111ee1ff5dc7"
      },
      "source": [
        "#看資料使否轉換正常\n",
        "train_data.shape,test_data.shape,train_label.shape, test_label.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m12v8LHROKL8"
      },
      "source": [
        "#建立model\n",
        "inc = tf.keras.applications.DenseNet201(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(256,256,3),\n",
        "    pooling='max',\n",
        ")\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        inc,\n",
        "        tf.keras.layers.Dense(512,activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(512,activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(64, activation='sigmoid')    \n",
        "    ])\n",
        "    return model\n",
        "    \n",
        "embedding_model = create_model()\n",
        "inc.summary(),embedding_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWr215kvEdyl"
      },
      "source": [
        "# 設定net的input樣式\n",
        "in_anc = tf.keras.layers.Input(shape=(256,256,3))\n",
        "in_pos = tf.keras.layers.Input(shape=(256,256,3))\n",
        "in_neg = tf.keras.layers.Input(shape=(256,256,3))\n",
        "\n",
        "#樣式輸入\n",
        "em_anc = embedding_model(in_anc)\n",
        "em_pos = embedding_model(in_pos)\n",
        "em_neg = embedding_model(in_neg)\n",
        "\n",
        "#把輸入連接起來\n",
        "out = tf.keras.layers.concatenate([em_anc,em_pos,em_neg],axis=1)\n",
        "\n",
        "net = tf.keras.models.Model(\n",
        "    [in_anc,in_pos,in_neg],\n",
        "    out\n",
        ")\n",
        "net.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAhZsamzKEi4"
      },
      "source": [
        "def create_batch_group(group_data,group_label,batch_size):\n",
        "    #建立目標數量大小的list\n",
        "    anchors = np.zeros((batch_size,256,256,3))\n",
        "    positives = np.zeros((batch_size,256,256,3))\n",
        "    negatives = np.zeros((batch_size,256,256,3))\n",
        "\n",
        "    #開始建立batch\n",
        "    for i in range(0,batch_size):\n",
        "        index = random.randint(0,(len(group_data)-1)) #隨機取一個圖片的位置\n",
        "        anc = group_data[index] #得到該圖片\n",
        "        y = group_label[index] #得到該圖片的數字\n",
        "\n",
        "        indices_for_pos = np.squeeze(np.where(group_label == y)) #所有與該圖片相同數字的位置\n",
        "        indices_for_neg = np.squeeze(np.where(group_label != y)) #所有與該圖片不相同數字的位置\n",
        "        \n",
        "        #上述位置隨機取一個圖片\n",
        "        pos = group_data[indices_for_pos[random.randint(0,len(indices_for_pos)-1)]] \n",
        "        neg = group_data[indices_for_neg[random.randint(0,len(indices_for_neg)-1)]]\n",
        "\n",
        "        anchors[i] = anc\n",
        "        positives[i] = pos\n",
        "        negatives[i] = neg\n",
        "\n",
        "    #回傳一個3列 size行的陣列\n",
        "    return [anchors,positives,negatives]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNjmwAQBqQ0s"
      },
      "source": [
        "#測試是否生出三張圖片\n",
        "temp = create_batch_group(train_data,train_label,1)\n",
        "plt.subplot(1,3,1)\n",
        "temp1 = tf.keras.preprocessing.image.array_to_img(temp[0][0])\n",
        "plt.imshow(temp1)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "temp1 = tf.keras.preprocessing.image.array_to_img(temp[1][0])\n",
        "plt.imshow(temp1)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "temp1 = tf.keras.preprocessing.image.array_to_img(temp[2][0])\n",
        "plt.imshow(temp1)\n",
        "plt.xticks([])\n",
        "plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rT0w6UzOfJM"
      },
      "source": [
        "def triplet_loss(alpha, emb_dim):\n",
        "    def loss(y_true,y_pred):\n",
        "        anc, pos, neg = y_pred[:, :emb_dim], y_pred[:, emb_dim:2*emb_dim], y_pred[:, 2*emb_dim:]\n",
        "        dp = tf.reduce_mean(tf.square(anc-pos), axis=1)\n",
        "        dn = tf.reduce_mean(tf.square(anc-neg), axis=1)\n",
        "        return tf.maximum(dp - dn +alpha,0.)\n",
        "    return loss\n",
        "    \n",
        "def data_generator(group_data, group_label, batch_size, emb_dim):\n",
        "    while True:\n",
        "      x = create_batch_group(group_data,group_label,batch_size)\n",
        "      y = np.zeros((batch_size, 3*emb_dim))\n",
        "      yield x, y "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPftk_aABR8Z"
      },
      "source": [
        "net.compile(loss = triplet_loss(alpha=0.2, emb_dim=64),optimizer='adam')\n",
        "LR_function = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1) #學習率調整\n",
        "history = net.fit(\n",
        "    data_generator(train_data,train_label,10,64),\n",
        "    epochs= 10, steps_per_epoch= len(train_data)//10,\n",
        "    validation_data = data_generator(train_data,train_label,10,64),\n",
        "    validation_steps = len(train_data)//10,\n",
        "    callbacks=[LR_function],\n",
        "    verbose = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}